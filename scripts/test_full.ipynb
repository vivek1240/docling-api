{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6abdd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # DocProcess API - Production Testing Notebook\n",
    "# \n",
    "# This script tests the production endpoints for:\n",
    "# - Latency measurements\n",
    "# - Accuracy validation\n",
    "# - API functionality\n",
    "# \n",
    "# Run each cell independently using VS Code's \"Run Cell\" or Cursor's interactive mode.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Setup & Configuration\n",
    "\n",
    "# %%\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "import statistics\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION - Update these values\n",
    "# =============================================================================\n",
    "\n",
    "# Production API URL (Railway)\n",
    "API_BASE_URL = \"https://web-production-00a7f.up.railway.app\"\n",
    "\n",
    "# Modal Direct URL (for comparison)\n",
    "MODAL_DIRECT_URL = \"https://vivek12345singh--docling-service-convert-endpoint.modal.run\"\n",
    "\n",
    "# Test documents\n",
    "TEST_DOCUMENTS = {\n",
    "    \"arxiv_docling\": \"https://arxiv.org/pdf/2501.17887\",  # Docling paper (8 pages)\n",
    "    \"arxiv_attention\": \"https://arxiv.org/pdf/1706.03762\",  # Attention paper (15 pages)\n",
    "    \"simple_pdf\": \"https://www.w3.org/WAI/WCAG21/Techniques/pdf/img/table-word.pdf\",  # Simple PDF\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035744dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give this to client: dk_n1rRM75COGQ_VpWz7kKa3XBvEwOTQKEJ2HvaF91xh6MSuvCexGiyIsk\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# You (admin) create a key\n",
    "response = requests.post(\n",
    "    \"https://web-production-00a7f.up.railway.app/v1/keys\",\n",
    "    json={\n",
    "        \"name\": \"Acme Corp\",      # Client name\n",
    "        \"tier\": \"starter\",         # Their plan\n",
    "        \"credits\": 500             # Initial credits\n",
    "    }\n",
    ")\n",
    "\n",
    "key_data = response.json()\n",
    "print(f\"Give this to client: {key_data['key']}\")\n",
    "# Output: dk_abc123_secretXYZ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3629747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4733a455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded\n",
      "   API URL: https://web-production-00a7f.up.railway.app\n",
      "   Modal URL: https://vivek12345singh--docling-service-convert-endpoint.modal.run\n"
     ]
    }
   ],
   "source": [
    "# Store results\n",
    "test_results = {\n",
    "    \"api_key\": None,\n",
    "    \"latency_tests\": [],\n",
    "    \"accuracy_tests\": [],\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuration loaded\")\n",
    "print(f\"   API URL: {API_BASE_URL}\")\n",
    "print(f\"   Modal URL: {MODAL_DIRECT_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368aa848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking API Health...\n",
      "--------------------------------------------------\n",
      "Status Code: 200\n",
      "Latency: 780.40ms\n",
      "Response: {\n",
      "  \"status\": \"healthy\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"docling_backend\": \"healthy\",\n",
      "  \"timestamp\": \"2026-01-23T21:08:45.400423\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 2. Health Check\n",
    "\n",
    "# %%\n",
    "def check_health():\n",
    "    \"\"\"Check API health status.\"\"\"\n",
    "    print(\"üîç Checking API Health...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    start = time.time()\n",
    "    response = requests.get(f\"{API_BASE_URL}/health\")\n",
    "    latency = (time.time() - start) * 1000\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Latency: {latency:.2f}ms\")\n",
    "    print(f\"Response: {json.dumps(data, indent=2)}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "health = check_health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e91e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Creating API Key...\n",
      "--------------------------------------------------\n",
      "Status Code: 201\n",
      "Key ID: dk_KiXNZlvd0m0\n",
      "API Key: dk_KiXNZlvd0m0_nmqnNI3ymJj7yjy...\n",
      "Credits: 500\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. Create API Key\n",
    "\n",
    "# %%\n",
    "def create_api_key(name: str = \"Test Key\", credits: int = 100):\n",
    "    \"\"\"Create a new API key for testing.\"\"\"\n",
    "    print(\"üîë Creating API Key...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/v1/keys\",\n",
    "        json={\"name\": name, \"credits\": credits}\n",
    "    )\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Key ID: {data.get('id')}\")\n",
    "    print(f\"API Key: {data.get('key', '')[:30]}...\")\n",
    "    print(f\"Credits: {data.get('credits')}\")\n",
    "    \n",
    "    # Store for later use\n",
    "    test_results[\"api_key\"] = data.get(\"key\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "key_data = create_api_key(\"Production Test\", credits=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5905e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Converting: https://arxiv.org/pdf/2501.17887...\n",
      "--------------------------------------------------\n",
      "‚úÖ Status: success\n",
      "üìÑ Pages: 8\n",
      "üìù Markdown Length: 37,147 chars\n",
      "‚è±Ô∏è  Total Latency: 42611.01ms (42.61s)\n",
      "üí∞ Credits Used: 8\n",
      "üí≥ Credits Remaining: 492\n",
      "\n",
      "üìä Performance Metrics:\n",
      "   Latency per page: 5326.38ms\n",
      "   Chars per page: 4643\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 4. Single Document Conversion Test\n",
    "\n",
    "# %%\n",
    "def convert_document(url: str, api_key: Optional[str] = None):\n",
    "    \"\"\"Convert a single document and measure performance.\"\"\"\n",
    "    api_key = api_key or test_results[\"api_key\"]\n",
    "    \n",
    "    print(f\"üìÑ Converting: {url[:50]}...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/v1/convert/source\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "        json={\n",
    "            \"sources\": [{\"kind\": \"http\", \"url\": url}],\n",
    "            \"options\": {\"output_format\": \"markdown\"}\n",
    "        },\n",
    "        timeout=300  # 5 minute timeout for large docs\n",
    "    )\n",
    "    \n",
    "    total_latency = (time.time() - start) * 1000\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    if response.status_code == 200 and \"results\" in data:\n",
    "        result = data[\"results\"][0]\n",
    "        markdown = result.get(\"markdown\", \"\")\n",
    "        \n",
    "        print(f\"‚úÖ Status: {result.get('status')}\")\n",
    "        print(f\"üìÑ Pages: {result.get('pages')}\")\n",
    "        print(f\"üìù Markdown Length: {len(markdown):,} chars\")\n",
    "        print(f\"‚è±Ô∏è  Total Latency: {total_latency:.2f}ms ({total_latency/1000:.2f}s)\")\n",
    "        print(f\"üí∞ Credits Used: {data.get('credits_used')}\")\n",
    "        print(f\"üí≥ Credits Remaining: {data.get('credits_remaining')}\")\n",
    "        \n",
    "        # Calculate per-page metrics\n",
    "        pages = result.get('pages', 1)\n",
    "        print(f\"\\nüìä Performance Metrics:\")\n",
    "        print(f\"   Latency per page: {total_latency/pages:.2f}ms\")\n",
    "        print(f\"   Chars per page: {len(markdown)/pages:.0f}\")\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"url\": url,\n",
    "            \"pages\": pages,\n",
    "            \"markdown_length\": len(markdown),\n",
    "            \"latency_ms\": total_latency,\n",
    "            \"latency_per_page_ms\": total_latency / pages,\n",
    "            \"credits_used\": data.get(\"credits_used\"),\n",
    "            \"markdown_preview\": markdown[:500]\n",
    "        }\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {data}\")\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"url\": url,\n",
    "            \"error\": data\n",
    "        }\n",
    "\n",
    "# Test with Docling paper\n",
    "result = convert_document(TEST_DOCUMENTS[\"arxiv_docling\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1f59bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'url': 'https://arxiv.org/pdf/2501.17887',\n",
       " 'pages': 8,\n",
       " 'markdown_length': 37147,\n",
       " 'latency_ms': 41583.43720436096,\n",
       " 'latency_per_page_ms': 5197.92965054512,\n",
       " 'credits_used': 8,\n",
       " 'markdown_preview': '## Docling: An Efficient Open-Source Toolkit for AI-driven Document Conversion\\n\\nNikolaos Livathinos * , Christoph Auer * , Maksym Lysak, Ahmed Nassar, Michele Dolfi, Panagiotis Vagenas, Cesar Berrospi, Matteo Omenetti, Kasper Dinkla, Yusik Kim, Shubham Gupta, Rafael Teixeira de Lima, Valery Weber, Lucas Morin, Ingmar Meijer, Viktor Kuropiatnyk, Peter W. J. Staar\\n\\nIBM Research, R¬® uschlikon, Switzerland\\n\\nPlease send correspondence to: deepsearch-core@zurich.ibm.com\\n\\n## Abstract\\n\\nWe introduce Docl'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6496ffc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è  Running Latency Benchmark...\n",
      "============================================================\n",
      "\n",
      "üîÑ Run 1/3\n",
      "   ‚úÖ 41537.37ms total, 5192.17ms/page\n",
      "\n",
      "üîÑ Run 2/3\n",
      "   ‚úÖ 8275.42ms total, 1034.43ms/page\n",
      "\n",
      "üîÑ Run 3/3\n",
      "   ‚úÖ 7551.53ms total, 943.94ms/page\n",
      "\n",
      "============================================================\n",
      "üìä LATENCY SUMMARY\n",
      "============================================================\n",
      "Runs: 3\n",
      "\n",
      "Total Latency:\n",
      "   Min: 7551.53ms\n",
      "   Max: 41537.37ms\n",
      "   Avg: 19121.44ms\n",
      "   Std: 19416.14ms\n",
      "\n",
      "Per-Page Latency:\n",
      "   Min: 943.94ms\n",
      "   Max: 5192.17ms\n",
      "   Avg: 2390.18ms\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 5. Latency Benchmark - Multiple Documents\n",
    "\n",
    "# %%\n",
    "def run_latency_benchmark(num_runs: int = 3):\n",
    "    \"\"\"Run multiple conversions to measure average latency.\"\"\"\n",
    "    print(\"‚è±Ô∏è  Running Latency Benchmark...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    api_key = test_results[\"api_key\"]\n",
    "    test_url = TEST_DOCUMENTS[\"arxiv_docling\"]\n",
    "    \n",
    "    latencies = []\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        print(f\"\\nüîÑ Run {i+1}/{num_runs}\")\n",
    "        \n",
    "        start = time.time()\n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/v1/convert/source\",\n",
    "            headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "            json={\n",
    "                \"sources\": [{\"kind\": \"http\", \"url\": test_url}],\n",
    "                \"options\": {\"output_format\": \"markdown\"}\n",
    "            },\n",
    "            timeout=300\n",
    "        )\n",
    "        latency = (time.time() - start) * 1000\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            pages = data[\"results\"][0].get(\"pages\", 1)\n",
    "            latencies.append({\n",
    "                \"run\": i + 1,\n",
    "                \"total_ms\": latency,\n",
    "                \"per_page_ms\": latency / pages,\n",
    "                \"pages\": pages\n",
    "            })\n",
    "            print(f\"   ‚úÖ {latency:.2f}ms total, {latency/pages:.2f}ms/page\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå Failed: {response.text[:100]}\")\n",
    "    \n",
    "    if latencies:\n",
    "        total_latencies = [l[\"total_ms\"] for l in latencies]\n",
    "        per_page_latencies = [l[\"per_page_ms\"] for l in latencies]\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä LATENCY SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Runs: {len(latencies)}\")\n",
    "        print(f\"\\nTotal Latency:\")\n",
    "        print(f\"   Min: {min(total_latencies):.2f}ms\")\n",
    "        print(f\"   Max: {max(total_latencies):.2f}ms\")\n",
    "        print(f\"   Avg: {statistics.mean(total_latencies):.2f}ms\")\n",
    "        if len(total_latencies) > 1:\n",
    "            print(f\"   Std: {statistics.stdev(total_latencies):.2f}ms\")\n",
    "        \n",
    "        print(f\"\\nPer-Page Latency:\")\n",
    "        print(f\"   Min: {min(per_page_latencies):.2f}ms\")\n",
    "        print(f\"   Max: {max(per_page_latencies):.2f}ms\")\n",
    "        print(f\"   Avg: {statistics.mean(per_page_latencies):.2f}ms\")\n",
    "        \n",
    "        test_results[\"latency_tests\"] = latencies\n",
    "    \n",
    "    return latencies\n",
    "\n",
    "# Run benchmark (adjust num_runs as needed)\n",
    "latency_results = run_latency_benchmark(num_runs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83b5acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Comparing Railway API vs Modal Direct...\n",
      "============================================================\n",
      "\n",
      "üì° Testing Railway API...\n",
      "   ‚úÖ Latency: 8535.31ms\n",
      "\n",
      "üöÄ Testing Modal Direct...\n",
      "   ‚úÖ Latency: 7555.90ms\n",
      "\n",
      "============================================================\n",
      "üìä COMPARISON RESULTS\n",
      "============================================================\n",
      "Railway API:   8535.31ms\n",
      "Modal Direct:  7555.90ms\n",
      "Overhead:      979.41ms (13.0%)\n",
      "\n",
      "Markdown lengths match: True\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 6. Compare: Railway API vs Modal Direct\n",
    "# %%\n",
    "def compare_railway_vs_modal():\n",
    "    \"\"\"Compare latency between Railway API and direct Modal call.\"\"\"\n",
    "    print(\"üîÑ Comparing Railway API vs Modal Direct...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    api_key = test_results[\"api_key\"]\n",
    "    test_url = TEST_DOCUMENTS[\"arxiv_docling\"]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Test Railway API\n",
    "    print(\"\\nüì° Testing Railway API...\")\n",
    "    start = time.time()\n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/v1/convert/source\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "        json={\n",
    "            \"sources\": [{\"kind\": \"http\", \"url\": test_url}],\n",
    "            \"options\": {\"output_format\": \"markdown\"}\n",
    "        },\n",
    "        timeout=300\n",
    "    )\n",
    "    railway_latency = (time.time() - start) * 1000\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results[\"railway\"] = {\n",
    "            \"latency_ms\": railway_latency,\n",
    "            \"pages\": data[\"results\"][0].get(\"pages\"),\n",
    "            \"markdown_len\": len(data[\"results\"][0].get(\"markdown\", \"\"))\n",
    "        }\n",
    "        print(f\"   ‚úÖ Latency: {railway_latency:.2f}ms\")\n",
    "    \n",
    "    # Test Modal Direct\n",
    "    print(\"\\nüöÄ Testing Modal Direct...\")\n",
    "    start = time.time()\n",
    "    response = requests.post(\n",
    "        MODAL_DIRECT_URL,\n",
    "        json={\"url\": test_url, \"output_format\": \"markdown\"},\n",
    "        timeout=300\n",
    "    )\n",
    "    modal_latency = (time.time() - start) * 1000\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results[\"modal\"] = {\n",
    "            \"latency_ms\": modal_latency,\n",
    "            \"pages\": data.get(\"pages\"),\n",
    "            \"markdown_len\": len(data.get(\"markdown\", \"\"))\n",
    "        }\n",
    "        print(f\"   ‚úÖ Latency: {modal_latency:.2f}ms\")\n",
    "    \n",
    "    # Comparison\n",
    "    if \"railway\" in results and \"modal\" in results:\n",
    "        overhead = results[\"railway\"][\"latency_ms\"] - results[\"modal\"][\"latency_ms\"]\n",
    "        overhead_pct = (overhead / results[\"modal\"][\"latency_ms\"]) * 100\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä COMPARISON RESULTS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Railway API:   {results['railway']['latency_ms']:.2f}ms\")\n",
    "        print(f\"Modal Direct:  {results['modal']['latency_ms']:.2f}ms\")\n",
    "        print(f\"Overhead:      {overhead:.2f}ms ({overhead_pct:.1f}%)\")\n",
    "        print(f\"\\nMarkdown lengths match: {results['railway']['markdown_len'] == results['modal']['markdown_len']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "comparison = compare_railway_vs_modal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced02d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 7. Accuracy Test - Content Validation\n",
    "\n",
    "# %%\n",
    "def test_accuracy():\n",
    "    \"\"\"Test accuracy by checking for expected content in converted documents.\"\"\"\n",
    "    print(\"üéØ Running Accuracy Tests...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    api_key = test_results[\"api_key\"]\n",
    "    \n",
    "    # Test cases: (url, expected_strings)\n",
    "    test_cases = [\n",
    "        {\n",
    "            \"name\": \"Docling Paper\",\n",
    "            \"url\": TEST_DOCUMENTS[\"arxiv_docling\"],\n",
    "            \"expected\": [\n",
    "                \"Docling\",\n",
    "                \"document conversion\",\n",
    "                \"IBM Research\",\n",
    "                \"PDF\",\n",
    "                \"table\",\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for test in test_cases:\n",
    "        print(f\"\\nüìÑ Testing: {test['name']}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        response = requests.post(\n",
    "            f\"{API_BASE_URL}/v1/convert/source\",\n",
    "            headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "            json={\n",
    "                \"sources\": [{\"kind\": \"http\", \"url\": test[\"url\"]}],\n",
    "                \"options\": {\"output_format\": \"markdown\"}\n",
    "            },\n",
    "            timeout=300\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            markdown = data[\"results\"][0].get(\"markdown\", \"\").lower()\n",
    "            \n",
    "            found = []\n",
    "            missing = []\n",
    "            \n",
    "            for expected in test[\"expected\"]:\n",
    "                if expected.lower() in markdown:\n",
    "                    found.append(expected)\n",
    "                else:\n",
    "                    missing.append(expected)\n",
    "            \n",
    "            accuracy = len(found) / len(test[\"expected\"]) * 100\n",
    "            \n",
    "            print(f\"   Found: {found}\")\n",
    "            if missing:\n",
    "                print(f\"   Missing: {missing}\")\n",
    "            print(f\"   Accuracy: {accuracy:.1f}%\")\n",
    "            \n",
    "            results.append({\n",
    "                \"name\": test[\"name\"],\n",
    "                \"found\": found,\n",
    "                \"missing\": missing,\n",
    "                \"accuracy\": accuracy\n",
    "            })\n",
    "        else:\n",
    "            print(f\"   ‚ùå Request failed: {response.status_code}\")\n",
    "    \n",
    "    test_results[\"accuracy_tests\"] = results\n",
    "    return results\n",
    "\n",
    "accuracy_results = test_accuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e73dc7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Load Test: 5 requests, 5 concurrent workers\n",
      "============================================================\n",
      "   ‚úÖ Request 0: 8008.76ms\n",
      "   ‚úÖ Request 3: 15044.88ms\n",
      "   ‚úÖ Request 4: 22387.75ms\n",
      "   ‚úÖ Request 2: 29411.95ms\n",
      "   ‚úÖ Request 1: 35934.61ms\n",
      "\n",
      "============================================================\n",
      "üìä LOAD TEST SUMMARY\n",
      "============================================================\n",
      "Total Requests: 5\n",
      "Successful: 5\n",
      "Failed: 0\n",
      "Success Rate: 100.0%\n",
      "\n",
      "Latency (successful requests):\n",
      "   Min: 8008.76ms\n",
      "   Max: 35934.61ms\n",
      "   Avg: 22157.59ms\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 8. Load Test - Multiple Concurrent Requests\n",
    "\n",
    "# %%\n",
    "import concurrent.futures\n",
    "\n",
    "def load_test(num_requests: int = 5, max_workers: int = 3):\n",
    "    \"\"\"Run multiple concurrent requests to test load handling.\"\"\"\n",
    "    print(f\"üî• Load Test: {num_requests} requests, {max_workers} concurrent workers\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    api_key = test_results[\"api_key\"]\n",
    "    test_url = TEST_DOCUMENTS[\"arxiv_docling\"]\n",
    "    \n",
    "    def make_request(request_id):\n",
    "        start = time.time()\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                f\"{API_BASE_URL}/v1/convert/source\",\n",
    "                headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "                json={\n",
    "                    \"sources\": [{\"kind\": \"http\", \"url\": test_url}],\n",
    "                    \"options\": {\"output_format\": \"markdown\"}\n",
    "                },\n",
    "                timeout=300\n",
    "            )\n",
    "            latency = (time.time() - start) * 1000\n",
    "            success = response.status_code == 200\n",
    "            return {\n",
    "                \"id\": request_id,\n",
    "                \"success\": success,\n",
    "                \"latency_ms\": latency,\n",
    "                \"status_code\": response.status_code\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"id\": request_id,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(make_request, i) for i in range(num_requests)]\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            status = \"‚úÖ\" if result.get(\"success\") else \"‚ùå\"\n",
    "            print(f\"   {status} Request {result['id']}: {result.get('latency_ms', 0):.2f}ms\")\n",
    "    \n",
    "    # Summary\n",
    "    successful = [r for r in results if r.get(\"success\")]\n",
    "    if successful:\n",
    "        latencies = [r[\"latency_ms\"] for r in successful]\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä LOAD TEST SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Total Requests: {num_requests}\")\n",
    "        print(f\"Successful: {len(successful)}\")\n",
    "        print(f\"Failed: {num_requests - len(successful)}\")\n",
    "        print(f\"Success Rate: {len(successful)/num_requests*100:.1f}%\")\n",
    "        print(f\"\\nLatency (successful requests):\")\n",
    "        print(f\"   Min: {min(latencies):.2f}ms\")\n",
    "        print(f\"   Max: {max(latencies):.2f}ms\")\n",
    "        print(f\"   Avg: {statistics.mean(latencies):.2f}ms\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run load test (adjust parameters as needed)\n",
    "# Warning: This uses credits!\n",
    "load_results = load_test(num_requests=5, max_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db082ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Load Test: 3 requests, 2 concurrent workers\n",
      "============================================================\n",
      "   ‚ùå Request 1: 5727.38ms\n",
      "   ‚ùå Request 2: 5592.51ms\n",
      "   ‚úÖ Request 0: 11861.00ms\n",
      "\n",
      "============================================================\n",
      "üìä LOAD TEST SUMMARY\n",
      "============================================================\n",
      "Total Requests: 3\n",
      "Successful: 1\n",
      "Failed: 2\n",
      "Success Rate: 33.3%\n",
      "\n",
      "Latency (successful requests):\n",
      "   Min: 11861.00ms\n",
      "   Max: 11861.00ms\n",
      "   Avg: 11861.00ms\n",
      "\n",
      "Failed requests details:\n",
      "  Request 1: status=500, error=None\n",
      "  Request 2: status=500, error=None\n"
     ]
    }
   ],
   "source": [
    "# Run the test\n",
    "load_results = load_test(num_requests=3, max_workers=2)\n",
    "\n",
    "# Then check the failures\n",
    "print(\"\\nFailed requests details:\")\n",
    "for r in load_results:\n",
    "    if not r.get(\"success\"):\n",
    "        print(f\"  Request {r['id']}: status={r.get('status_code')}, error={r.get('error')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4733774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed request details:\n",
      "  Request 1: status=500\n",
      "  Request 2: status=500\n",
      "Status: 200\n"
     ]
    }
   ],
   "source": [
    "# Check what the server is returning for failures\n",
    "print(\"Failed request details:\")\n",
    "for r in load_results:\n",
    "    if not r.get(\"success\"):\n",
    "        print(f\"  Request {r['id']}: status={r.get('status_code')}\")\n",
    "\n",
    "# Let's make a test request with full response capture\n",
    "import requests\n",
    "api_key = test_results[\"api_key\"]\n",
    "test_url = TEST_DOCUMENTS[\"arxiv_docling\"]\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{API_BASE_URL}/v1/convert/source\",\n",
    "    headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "    json={\n",
    "        \"sources\": [{\"kind\": \"http\", \"url\": test_url}],\n",
    "        \"options\": {\"output_format\": \"markdown\"}\n",
    "    },\n",
    "    timeout=300\n",
    ")\n",
    "print(f\"Status: {response.status_code}\")\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error body: {response.text}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538891f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56c7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e2d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4225f043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed requests:\n",
      "  Request 0: status=500, error=None\n",
      "  Request 2: status=500, error=None\n"
     ]
    }
   ],
   "source": [
    "# Check what errors occurred\n",
    "print(\"Failed requests:\")\n",
    "for r in load_results:\n",
    "    if not r.get(\"success\"):\n",
    "        print(f\"  Request {r['id']}: status={r.get('status_code')}, error={r.get('error')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc092d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 9. Check Remaining Credits\n",
    "\n",
    "# %%\n",
    "def check_credits():\n",
    "    \"\"\"Check remaining credits for the API key.\"\"\"\n",
    "    print(\"üí≥ Checking Credits...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    api_key = test_results[\"api_key\"]\n",
    "    \n",
    "    # Make a request to get credits info\n",
    "    response = requests.get(\n",
    "        f\"{API_BASE_URL}/v1/usage\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        print(f\"Response: {json.dumps(data, indent=2)}\")\n",
    "    else:\n",
    "        print(f\"Status: {response.status_code}\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "    \n",
    "    return response.json() if response.status_code == 200 else None\n",
    "\n",
    "credits_info = check_credits()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## 10. Final Summary Report\n",
    "\n",
    "# %%\n",
    "def generate_report():\n",
    "    \"\"\"Generate a final summary report of all tests.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"üìã FINAL TEST REPORT\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"API URL: {API_BASE_URL}\")\n",
    "    \n",
    "    print(\"\\nüîë API KEY\")\n",
    "    print(\"-\" * 40)\n",
    "    if test_results[\"api_key\"]:\n",
    "        print(f\"   Key: {test_results['api_key'][:30]}...\")\n",
    "    \n",
    "    print(\"\\n‚è±Ô∏è  LATENCY TESTS\")\n",
    "    print(\"-\" * 40)\n",
    "    if test_results[\"latency_tests\"]:\n",
    "        latencies = [t[\"total_ms\"] for t in test_results[\"latency_tests\"]]\n",
    "        print(f\"   Runs: {len(latencies)}\")\n",
    "        print(f\"   Average: {statistics.mean(latencies):.2f}ms\")\n",
    "        print(f\"   Range: {min(latencies):.2f}ms - {max(latencies):.2f}ms\")\n",
    "    \n",
    "    print(\"\\nüéØ ACCURACY TESTS\")\n",
    "    print(\"-\" * 40)\n",
    "    if test_results[\"accuracy_tests\"]:\n",
    "        for test in test_results[\"accuracy_tests\"]:\n",
    "            print(f\"   {test['name']}: {test['accuracy']:.1f}%\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ Testing Complete!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "generate_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b0a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Bonus: Quick Test Function\n",
    "\n",
    "# %%\n",
    "def quick_test(url: str):\n",
    "    \"\"\"Quick function to test any URL.\"\"\"\n",
    "    api_key = test_results[\"api_key\"]\n",
    "    if not api_key:\n",
    "        print(\"‚ùå No API key. Run cell 3 first!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üöÄ Quick converting: {url}\")\n",
    "    start = time.time()\n",
    "    \n",
    "    response = requests.post(\n",
    "        f\"{API_BASE_URL}/v1/convert/source\",\n",
    "        headers={\"Authorization\": f\"Bearer {api_key}\"},\n",
    "        json={\n",
    "            \"sources\": [{\"kind\": \"http\", \"url\": url}],\n",
    "            \"options\": {\"output_format\": \"markdown\"}\n",
    "        },\n",
    "        timeout=300\n",
    "    )\n",
    "    \n",
    "    latency = time.time() - start\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        result = data[\"results\"][0]\n",
    "        print(f\"‚úÖ Done in {latency:.2f}s\")\n",
    "        print(f\"   Pages: {result.get('pages')}\")\n",
    "        print(f\"   Length: {len(result.get('markdown', '')):,} chars\")\n",
    "        return result.get(\"markdown\")\n",
    "    else:\n",
    "        print(f\"‚ùå Error: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# markdown = quick_test(\"https://example.com/document.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b24a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bbe17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe3a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f06498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773f35a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275a3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c42eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Success! Pages: 1\n",
      "üìù Markdown preview:\n",
      "<!-- image -->\n",
      "\n",
      "Dear Vivek,\n",
      "\n",
      "Pursuant to the ending of your employment with us, you are herewith relieved from the services of Expedite Commerce India with effect from the close of business hours on April 10th, 2025.\n",
      "\n",
      "We confirm that you were employed with Expedite Commerce from January 27th, 2025, to April 10th, 2025, and your designation at the time of leaving was AI LLM Agent Engineer\n",
      "\n",
      ".\n",
      "\n",
      "We wish you all the best in your future career endeavors.\n",
      "\n",
      "Best Regards,\n",
      "\n",
      "Brett Larson Chief People Offic...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Configuration\n",
    "API_URL = \"https://web-production-00a7f.up.railway.app\"\n",
    "API_KEY = \"dk_n1rRM75COGQ_VpWz7kKa3XBvEwOTQKEJ2HvaF91xh6MSuvCexGiyIsk\"  # Your client's key\n",
    "\n",
    "# PDF URL (can be S3, Google Drive, Dropbox, any public URL)\n",
    "pdf_url = \"https://drive.google.com/file/d/1H3poYQBzkHcqvD_HjVJrtVzHCJEPqwl-/view?usp=sharing\"  # Docling paper\n",
    "\n",
    "# Convert\n",
    "response = requests.post(\n",
    "    f\"{API_URL}/v1/convert/source\",\n",
    "    headers={\"Authorization\": f\"Bearer {API_KEY}\"},\n",
    "    json={\n",
    "        \"sources\": [{\"kind\": \"http\", \"url\": pdf_url}],\n",
    "        \"options\": {\"output_format\": \"markdown\"}\n",
    "    },\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "# Result\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    markdown = data[\"results\"][0][\"markdown\"]\n",
    "    print(f\"‚úÖ Success! Pages: {data['results'][0]['pages']}\")\n",
    "    print(f\"üìù Markdown preview:\\n{markdown[:500]}...\")\n",
    "else:\n",
    "    print(f\"‚ùå Error: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3654268d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!-- image -->\\n\\nDear Vivek,\\n\\nPursuant to the ending of your employment with us, you are herewith relieved from the services of Expedite Commerce India with effect from the close of business hours on April 10th, 2025.\\n\\nWe confirm that you were employed with Expedite Commerce from January 27th, 2025, to April 10th, 2025, and your designation at the time of leaving was AI LLM Agent Engineer\\n\\n.\\n\\nWe wish you all the best in your future career endeavors.\\n\\nBest Regards,\\n\\nBrett Larson Chief People Officer\\n\\n<!-- image -->'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8652b54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (docling_api)",
   "language": "python",
   "name": "docling_api"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
